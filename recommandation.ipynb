{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb37b93-ae83-495c-9f9f-0c2297746c1e",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ddf21-6fb0-49af-a712-c75323d4b27a",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879f7af-713d-4bf8-badc-40986f6b771d",
   "metadata": {},
   "source": [
    "+ Number of customers predicted by the model as ‚Äúwill purchase‚Äù: 1,714\n",
    "+ Number of correct ‚Äúwill purchase‚Äù predictions (True Positives): 112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37ab14-1114-465a-a5d3-e81524807f44",
   "metadata": {},
   "source": [
    "## Metrics Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257261a-6044-4985-8a35-cb723ab8eeec",
   "metadata": {},
   "source": [
    "Meaning in Recommendation Systems\n",
    "+ Recall (Class 1)\n",
    "Among all users who actually made a purchase, the proportion correctly identified by the model.\n",
    "+ Precision (Class 1)\n",
    "Among all users recommended by the model, the proportion who actually made a purchase.\n",
    "+ F1-score\n",
    "A combined measure of recommendation capability that balances both precision and recall.\n",
    "+ AUC (optional)\n",
    "Overall performance across different classification thresholds (more robust for imbalanced datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1b3f2-2acb-4ad7-9cd6-099ed1815ebd",
   "metadata": {},
   "source": [
    "## Analysis of Actual Promotion Cost vs. Effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571d56c-5646-4ad8-b544-16d08fd6c0b6",
   "metadata": {},
   "source": [
    "Suppose a company have 100,000 existing users and select 1,714 of them for targeted recommendations or email promotions:\n",
    "\n",
    "üåü Effectiveness Evaluation:\n",
    "\n",
    "For every 100 users recommended, about 6‚Äì7 will make a purchase (precision).\n",
    "\n",
    "This is a fairly common baseline:\n",
    "\n",
    "+ For most e-commerce cold-start recommendations, the click-through rate (CTR) is below 1%, and the conversion rate (CVR) is below 5%.\n",
    "+ Your model‚Äôs recommended conversion rate is around 6‚Äì7%, significantly higher than random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb654b-156e-4a75-81c4-e5336c944e07",
   "metadata": {},
   "source": [
    "## Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e3380-bff0-4e3c-bb17-f0789f53e730",
   "metadata": {},
   "source": [
    "1. Two-Tower Retrieval Recommendation Model: Built a recall system incorporating user/item embeddings, enriched with contextual information such as time, location, and company.\n",
    "2.\tNew Product Cold-Start Prediction Task: Modeled purchase likelihood for unseen products by reusing user embeddings in combination with an MLP and Focal Loss.\n",
    "3.\tData Engineering & Sample Construction: Generated positive/negative samples from historical user behaviors, addressed class imbalance, and evaluated model performance using metrics such as HitRate@K, Precision, and Recall.\n",
    "4.\tComparative Analysis with Multiple Models: Evaluated and compared models including Logistic Regression, MLP, and PyTorch-based implementations, clearly demonstrating the cold-start challenges and the impact of model choice on results.\n",
    "5.\tHigh Extensibility: The project can be further extended to support ranking models, item-to-item recall, and advanced features such as multimodal inputs (product text/images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839f9670-3571-410d-8762-39b09d028456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9d7e1c4-4d48-41c9-9383-c39ce2edc1d4",
   "metadata": {},
   "source": [
    "# 1. Get data\n",
    "read data and clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08be032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb4fa87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['May-19',\n",
       " 'indoor_garden_preferencere_sponses.csv',\n",
       " '.DS_Store',\n",
       " 'List Export 2025-04-08.csv',\n",
       " 'df_until_May_19.csv',\n",
       " 'May-15',\n",
       " 'category_df_fillna.csv',\n",
       " 'df_user_profile.csv',\n",
       " 'Bundle-Orders-2025-5-16.csv',\n",
       " 'orders_export_all.csv',\n",
       " 'orders_export_2.csv',\n",
       " 'orders_export_1.csv',\n",
       " 'landingpage-2025-04-01-2025-05-23.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf3558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/df_until_May_19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987f4400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-05-19 09:28:55-05:00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Created at\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02d79f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705801, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d21bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389050"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orderid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50185353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderid', 'Email', 'Lineitem sku', 'Lineitem name', 'Lineitem price',\n",
       "       'Subtotal', 'Shipping', 'Taxes', 'Total', 'Discount Amount',\n",
       "       'Created at', 'Lineitem quantity', 'Lineitem compare at price',\n",
       "       'Shipping Name', 'Shipping Street', 'Shipping Address1',\n",
       "       'Shipping Address2', 'Shipping Company', 'Shipping City',\n",
       "       'Shipping Zip', 'Shipping Province', 'Shipping Country',\n",
       "       'Shipping Phone', 'Vendor', 'Year', 'Month', 'Day', 'Hour', 'type name',\n",
       "       'Parent_SKU', 'Product Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae58f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a3b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Product Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df13d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Created at\"] = pd.to_datetime(df[\"Created at\"], utc=True)\n",
    "# Â∞Ü UTC Êó∂Èó¥ËΩ¨Êç¢‰∏∫ÁæéÂõΩ‰∏≠ÈÉ®Êó∂Èó¥ÔºàCST/CDTÔºâ\n",
    "df[\"Created at\"] = df[\"Created at\"].dt.tz_convert('America/Chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd7213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Shipping Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec09a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Shipping Country\"]==\"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a16785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700915, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbf7d2",
   "metadata": {},
   "source": [
    "# 2. Plan Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66aeb6a",
   "metadata": {},
   "source": [
    "## 1.Two-Tower Retrieval Model: (Completed)\n",
    "\n",
    "+ Left Tower (User Tower): Email (can be encoded as user_id), shipping country/province/city, time features (year, month, day, hour), etc.\n",
    "+ Right Tower (Item Tower): Lineitem SKU, lineitem name, vendor, product type, price, discount, etc.\n",
    "\n",
    "Used to construct a user‚Äìitem embedding space and perform retrieval by computing vector similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff7904",
   "metadata": {},
   "source": [
    "## 2.Ranking Model: (Not applied due to limited number of products, use simpler model instead)\n",
    "\n",
    "Built on top of the retrieval stage, a ranking model would leverage richer features such as:\n",
    "+ User-side: Address, order time, historical behavioral statistics (e.g., number of orders in the past 30 days)\n",
    "+ Item-side: Price, discount, category, sales volume, etc.\n",
    "\n",
    "Possible model architectures include Wide & Deep, DNN, DCN, and DIN, and TFRS also supports custom ranking models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a9d49",
   "metadata": {},
   "source": [
    "## 3. Sequential Modeling (Optional)\n",
    "+ Construct click/purchase sequences for each user, using models such as:\n",
    "+ GRU4Rec, SASRec, or Transformer-based recommendation models\n",
    "+ TFRS also supports this type of RNN-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831535ad",
   "metadata": {},
   "source": [
    "# 3. Preparation for verification data \n",
    "+ find the new product launch time\n",
    "+ thus can use the model and data previous this launch time to predict which old user will buy the new product\n",
    "+ then verify it with the real data after the lauch time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a486dd1",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## used: check new product lanuch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1320186c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Á°Æ‰øù 'Created at' ÊòØ datetime Ê†ºÂºè\n",
    "df['Created at'] = pd.to_datetime(df['Created at'])\n",
    "\n",
    "# ÂàÜÁªÑËÅöÂêàÊúÄÊó©ÂíåÊúÄÊôöÊó∂Èó¥\n",
    "product_lifecycle = df.groupby('type name')['Created at'].agg(\n",
    "    first_order_date='min',\n",
    "    last_order_date='max'\n",
    ").reset_index()\n",
    "\n",
    "# ÂèØÈÄâÔºöËÆ°ÁÆóÁîüÂëΩÂë®ÊúüÈïøÂ∫¶ÔºàÂçï‰ΩçÔºöÂ§©Ôºâ\n",
    "product_lifecycle['days_between'] = (product_lifecycle['last_order_date'] - product_lifecycle['first_order_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0fdd7fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# product_lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4ff02a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# product_lifecycle[\"days_between\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26da4ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3346"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"type name\"]==\"EZ Self-Watering Herb Planter Box with Trellis\"][\"Lineitem quantity\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2db2b01c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3346/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01b6600f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1703727.01"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"type name\"]==\"EZ Self-Watering Herb Planter Box with Trellis\"][\"Total\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c038de1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737708.67"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df[\"type name\"]==\"EZ Self-Watering Mini Planter Pot with Trellis\"][\"Total\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "769f6a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df[df[\"type name\"]==\"EZ Self-Watering Tomato Planter with Trellis\"][\"Total\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ee7fc7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_products=[\"EZ Self-Watering Herb Planter Box with Trellis\"\n",
    "\"EZ Self-Watering Mini Planter Pot with Trellis\"\n",
    "\"EZ Self-Watering Tomato Planter with Trellis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15c57972",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type name</th>\n",
       "      <th>first_order_date</th>\n",
       "      <th>last_order_date</th>\n",
       "      <th>days_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>EZ Self-Watering Herb Planter Box with Trellis</td>\n",
       "      <td>2025-01-14 07:08:36-06:00</td>\n",
       "      <td>2025-05-19 08:44:03-05:00</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>EZ Self-Watering Mini Planter Pot with Trellis</td>\n",
       "      <td>2025-01-14 13:41:23-06:00</td>\n",
       "      <td>2025-05-19 09:00:01-05:00</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>EZ Self-Watering Tomato Planter with Trellis</td>\n",
       "      <td>2025-01-15 08:19:27-06:00</td>\n",
       "      <td>2025-05-19 08:36:43-05:00</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Vego Irrigation Kit</td>\n",
       "      <td>2025-01-20 21:13:37-06:00</td>\n",
       "      <td>2025-05-19 09:28:52-05:00</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>EZ Self-Watering Home Planter</td>\n",
       "      <td>2025-01-25 15:31:07-06:00</td>\n",
       "      <td>2025-05-18 19:18:11-05:00</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Shipping Protection by Route</td>\n",
       "      <td>2025-01-29 02:57:32-06:00</td>\n",
       "      <td>2025-05-19 09:28:55-05:00</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Elevated garden bed wheel set</td>\n",
       "      <td>2025-02-01 05:04:40-06:00</td>\n",
       "      <td>2025-05-18 14:23:27-05:00</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Improved Meyer Lemon Bush</td>\n",
       "      <td>2025-02-02 17:30:49-06:00</td>\n",
       "      <td>2025-05-18 13:07:32-05:00</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>Plant 'n' Pop Seed Bundle</td>\n",
       "      <td>2025-02-05 12:35:38-06:00</td>\n",
       "      <td>2025-05-19 09:08:02-05:00</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>Seed Starting Bundle with Lid</td>\n",
       "      <td>2025-02-07 04:43:06-06:00</td>\n",
       "      <td>2025-05-18 22:27:33-05:00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           type name  \\\n",
       "493   EZ Self-Watering Herb Planter Box with Trellis   \n",
       "496   EZ Self-Watering Mini Planter Pot with Trellis   \n",
       "497     EZ Self-Watering Tomato Planter with Trellis   \n",
       "1417                             Vego Irrigation Kit   \n",
       "495                    EZ Self-Watering Home Planter   \n",
       "1184                    Shipping Protection by Route   \n",
       "519                    Elevated garden bed wheel set   \n",
       "715                        Improved Meyer Lemon Bush   \n",
       "1010                       Plant 'n' Pop Seed Bundle   \n",
       "1162                   Seed Starting Bundle with Lid   \n",
       "\n",
       "              first_order_date           last_order_date  days_between  \n",
       "493  2025-01-14 07:08:36-06:00 2025-05-19 08:44:03-05:00           125  \n",
       "496  2025-01-14 13:41:23-06:00 2025-05-19 09:00:01-05:00           124  \n",
       "497  2025-01-15 08:19:27-06:00 2025-05-19 08:36:43-05:00           123  \n",
       "1417 2025-01-20 21:13:37-06:00 2025-05-19 09:28:52-05:00           118  \n",
       "495  2025-01-25 15:31:07-06:00 2025-05-18 19:18:11-05:00           113  \n",
       "1184 2025-01-29 02:57:32-06:00 2025-05-19 09:28:55-05:00           110  \n",
       "519  2025-02-01 05:04:40-06:00 2025-05-18 14:23:27-05:00           106  \n",
       "715  2025-02-02 17:30:49-06:00 2025-05-18 13:07:32-05:00           104  \n",
       "1010 2025-02-05 12:35:38-06:00 2025-05-19 09:08:02-05:00           102  \n",
       "1162 2025-02-07 04:43:06-06:00 2025-05-18 22:27:33-05:00           100  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_lifecycle[product_lifecycle[\"first_order_date\"]>\"2025-01-01 09:09:04-05:00\"].sort_values(by=\"days_between\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc81d9d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# product_lifecycle.sort_values(by=\"days_between\",ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed00d8ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# product_lifecycle.sort_values(by=[\"first_order_date\",ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33915aaf",
   "metadata": {},
   "source": [
    "## new product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e72ddad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3341"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"type name\"]==\"EZ Self-Watering Herb Planter Box with Trellis\"][\"Lineitem quantity\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9cf8999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1701982.02"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"type name\"]==\"EZ Self-Watering Herb Planter Box with Trellis\"][\"Total\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5140f",
   "metadata": {},
   "source": [
    "## split data, before and after launch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3517773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = df[df[\"Created at\"]<\"2025-01-14 01:08:36-06:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb154ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-09-29 18:47:42-0500', tz='America/Chicago'),\n",
       " Timestamp('2025-01-14 00:49:49-0600', tz='America/Chicago'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_before[\"Created at\"].min(), df_before[\"Created at\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06c947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after = df[df[\"Created at\"]>\"2025-01-15 01:08:36-06:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f4baed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2025-01-15 01:51:45-0600', tz='America/Chicago'),\n",
       " Timestamp('2025-05-19 09:28:55-0500', tz='America/Chicago'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after[\"Created at\"].min(), df_after[\"Created at\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145c398",
   "metadata": {},
   "source": [
    "# 4. Model and Data structure Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "829ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7dfc59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "v0.7.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tfrs.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef97375-3622-42b2-bdc6-e2569cf08bab",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdc160ad-0bff-45cb-abdf-244d890bc496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h1/kkr0d8_n4414qhwr_pl231w00000gn/T/ipykernel_53326/2190089378.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_before[\"hour\"] = df_before[\"Hour\"].astype(str)\n",
      "/var/folders/h1/kkr0d8_n4414qhwr_pl231w00000gn/T/ipykernel_53326/2190089378.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_before[\"month\"] = df_before[\"Month\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# 1. ‰øùËØÅÂ≠óÊÆµÊòØ string Á±ªÂûã\n",
    "df_before[\"hour\"] = df_before[\"Hour\"].astype(str)\n",
    "df_before[\"month\"] = df_before[\"Month\"].astype(str)\n",
    "\n",
    "# 2. ÊãüÂêà‰ª∑Ê†ºÂΩí‰∏ÄÂåñÂô®\n",
    "price_norm = tf.keras.layers.Normalization(axis=None)\n",
    "price_norm.adapt(df_before[\"Lineitem price\"].values.astype(\"float32\"))\n",
    "\n",
    "# 3. ÂàõÂª∫ÂéüÂßãÁâπÂæÅÁöÑ Dataset\n",
    "features_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": df_before[\"Email\"].astype(str),\n",
    "    \"province\": df_before[\"Shipping Province\"].astype(str),\n",
    "    \"city\": df_before[\"Shipping City\"].astype(str),\n",
    "    \"company\": df_before[\"Shipping Company\"].astype(str),\n",
    "    \"hour\": df_before[\"hour\"],\n",
    "    \"month\": df_before[\"month\"],\n",
    "    \"item_id\": df_before[\"Lineitem name\"].astype(str),\n",
    "    \"type\": df_before[\"type name\"].astype(str),\n",
    "    \"price\": df_before[\"Lineitem price\"].astype(\"float32\"),\n",
    "})\n",
    "\n",
    "# 4. ËΩ¨Êç¢‰∏∫ TFRS Ê®°ÂûãÊâÄÈúÄÊ†ºÂºèÔºö(features_dict, item_id)\n",
    "# Ê≥®ÊÑèËøôÈáåÁöÑÊ†áÁ≠æ‰∏∫ item_idÔºåÁî®‰∫é Retrieval Â≠¶‰π†ÁõÆÊ†á\n",
    "train_ds = features_ds.map(lambda x: (x, x[\"item_id\"]))\n",
    "\n",
    "# 5. Shuffle, batch, prefetch\n",
    "train_ds = train_ds.shuffle(100_000).batch(1024).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39ccd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_ds = item_ds.apply(tf.data.experimental.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46500f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec={'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'province': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'city': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'company': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'hour': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'month': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'item_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'price': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252db1ac",
   "metadata": {},
   "source": [
    "## two tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d50d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(tfrs.models.Model):\n",
    "    def __init__(self, user_model, item_model, candidate_ds):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(candidates=candidate_ds.batch(128).map(item_model))\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_features, item_id = features  # Ëß£ÂåÖ tuple\n",
    "    \n",
    "        user_embedding = self.user_model({\n",
    "            \"user_id\": user_features[\"user_id\"],\n",
    "            \"province\": user_features[\"province\"],\n",
    "            \"city\": user_features[\"city\"],\n",
    "            \"company\": user_features[\"company\"],\n",
    "            \"hour\": user_features[\"hour\"],\n",
    "            \"month\": user_features[\"month\"],\n",
    "        })\n",
    "    \n",
    "        item_embedding = self.item_model({\n",
    "            \"item_id\": item_id,\n",
    "            \"type\": user_features[\"type\"],\n",
    "            \"price\": user_features[\"price\"],\n",
    "        })\n",
    "    \n",
    "        return self.task(user_embedding, item_embedding)\n",
    "\n",
    "    # Ê∑ªÂä† call ÊñπÊ≥ïÔºåËÆ© Keras Áü•ÈÅìÂâçÂêëÁªìÊûÑ\n",
    "    def call(self, features):\n",
    "        return {\n",
    "            \"user_embedding\": self.user_model({\n",
    "                \"user_id\": features[\"user_id\"],\n",
    "                \"province\": features[\"province\"],\n",
    "                \"city\": features[\"city\"],\n",
    "                \"company\": features[\"company\"],\n",
    "                \"hour\": features[\"hour\"],\n",
    "                \"month\": features[\"month\"],\n",
    "            }),\n",
    "            \"item_embedding\": self.item_model({\n",
    "                \"item_id\": features[\"item_id\"],\n",
    "                \"type\": features[\"type\"],\n",
    "                \"price\": features[\"price\"],\n",
    "            }),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc72a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8dd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a07d19",
   "metadata": {},
   "source": [
    "## user tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d5b652f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self, user_ids, provinces, cities, companies, hours, months, embedding_dim=32, output_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_id_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(user_ids) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.province_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=provinces, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(provinces) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.city_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=cities, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(cities) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.company_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=companies, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(companies) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.hour_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=hours, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(hours) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.month_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=months, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(months) + 1, embedding_dim)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim)  # ÊäïÂΩ±‰∏∫Áªü‰∏ÄÁª¥Â∫¶\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False, cold_start=False):\n",
    "        user_id_emb = self.user_id_lookup(inputs[\"user_id\"])\n",
    "        province_emb = self.province_lookup(inputs[\"province\"])\n",
    "        city_emb = self.city_lookup(inputs[\"city\"])\n",
    "        company_emb = self.company_lookup(inputs[\"company\"])\n",
    "        hour_emb = self.hour_lookup(inputs[\"hour\"])\n",
    "        month_emb = self.month_lookup(inputs[\"month\"])\n",
    "\n",
    "        # Ê®°Êãü cold startÔºöËÆ≠ÁªÉÊó∂ DropoutÔºåÈ¢ÑÊµãÊó∂ cold_start ÂèÇÊï∞ÊéßÂà∂\n",
    "        if training:\n",
    "            user_id_emb = tf.keras.layers.Dropout(0.3)(user_id_emb)\n",
    "        elif cold_start:\n",
    "            user_id_emb = tf.zeros_like(user_id_emb)\n",
    "\n",
    "        x = tf.concat([\n",
    "            user_id_emb,\n",
    "            province_emb,\n",
    "            city_emb,\n",
    "            company_emb,\n",
    "            hour_emb,\n",
    "            month_emb\n",
    "        ], axis=1)\n",
    "\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf63c36",
   "metadata": {},
   "source": [
    "## product tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2add2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "    def __init__(self, item_ids, item_types, embedding_dim=32, output_dim=64):\n",
    "        super().__init__()\n",
    "        self.item_id_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=item_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(item_ids) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.type_lookup = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=item_types, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(item_types) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.price_norm = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim)  # ÊäïÂΩ±‰∏∫Áªü‰∏ÄÁª¥Â∫¶\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.concat([\n",
    "            self.item_id_lookup(inputs[\"item_id\"]),\n",
    "            self.type_lookup(inputs[\"type\"]),\n",
    "            tf.expand_dims(self.price_norm(inputs[\"price\"]), axis=1),\n",
    "        ], axis=1)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b83a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d9faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889a7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c55a8b0c",
   "metadata": {},
   "source": [
    "# 5.Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e93b9b5-345d-4ddd-aba7-1c67f047035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_user_ids = set(df_before[\"Email\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce7ad668-a2de-4437-9dc8-0b6fb9a40bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = df[\"Email\"].astype(str).unique().tolist()\n",
    "provinces = df[\"Shipping Province\"].astype(str).unique().tolist()\n",
    "cities = df[\"Shipping City\"].astype(str).unique().tolist()\n",
    "companies = df[\"Shipping Company\"].astype(str).unique().tolist()\n",
    "hours = df[\"Hour\"].astype(str).unique().tolist()\n",
    "months = df[\"Month\"].astype(str).unique().tolist()\n",
    "\n",
    "item_ids = df[\"Lineitem name\"].astype(str).unique().tolist()\n",
    "item_types = df[\"type name\"].astype(str).unique().tolist()\n",
    "# item_price = df[\"Lineitem price\"].astype(str).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4b4a1-534c-4fee-bf4f-ba7865f3880e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ac61538-b720-471f-9c7e-7e32bc464ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = UserModel(unique_user_ids, provinces, cities, companies, hours, months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "77a1cbe4-454f-42ad-8c25-e3cd4f441362",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model = ItemModel(item_ids, item_types)\n",
    "item_model.price_norm.adapt(df[\"Lineitem price\"].astype(\"float32\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44604c0b-0209-4a0c-8007-d52a45ec705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áî® pandas ÂÖàÂéªÈáçÔºåÈÄâÂèñ item ÁâπÂæÅ\n",
    "item_df = df_before[[\"Lineitem name\", \"type name\", \"Lineitem price\"]].drop_duplicates()\n",
    "\n",
    "# ÊûÑÂª∫ candidate_dsÔºåÂåÖÂê´ item_id, type, price\n",
    "candidate_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"item_id\": item_df[\"Lineitem name\"].astype(str).values,\n",
    "    \"type\": item_df[\"type name\"].astype(str).values,\n",
    "    \"price\": item_df[\"Lineitem price\"].astype(\"float32\").values,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9ccaf3b4-ce11-4c9c-9f0a-f092a10f13ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    }
   ],
   "source": [
    "model = TwoTowerModel(user_model, item_model, candidate_ds=candidate_ds)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "85153bcf-7442-4be5-bb72-649e0ba8aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b\"Vego Garden Pacific Greenhouse - 8.5' x 16.5'\"\n",
      " b\"Vego Garden Pacific Greenhouse - 8.5' x 16.5'\"\n",
      " b\"Vego Garden Pacific Greenhouse - 8.5' x 16.5'\"\n",
      " b\"Vego Garden Pacific Greenhouse - 8.5' x 12.5'\"\n",
      " b\"Vego Garden Pacific Greenhouse - 8.5' x 10.5'\"]\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫ BruteForce Ê£ÄÁ¥¢Â±Ç\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    candidate_ds.batch(128).map(lambda x: (x[\"item_id\"], model.item_model(x)))\n",
    ")\n",
    "\n",
    "# ÊµãËØï‰∏Ä‰∏™Áî®Êà∑\n",
    "test_user = {\n",
    "    \"user_id\": tf.constant([\"some_user_id\"]),\n",
    "    \"province\": tf.constant([\"CA\"]),\n",
    "    \"city\": tf.constant([\"San Francisco\"]),\n",
    "    \"company\": tf.constant([\"Acme Inc\"]),\n",
    "    \"hour\": tf.constant([\"14\"]),\n",
    "    \"month\": tf.constant([\"6\"])\n",
    "}\n",
    "scores, items = index(test_user)\n",
    "print(\"Top recommendations:\", items[0, :5].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e51bc2-d876-4ee5-9be7-fcfd1ad6eceb",
   "metadata": {},
   "source": [
    "Stopped the training process manually when no further model improvement was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eae116bb-e7d8-4fdf-bf2f-610e66ea3a12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "472/472 [==============================] - 127s 268ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0816 - factorized_top_k/top_5_categorical_accuracy: 0.2018 - factorized_top_k/top_10_categorical_accuracy: 0.2913 - factorized_top_k/top_50_categorical_accuracy: 0.6513 - factorized_top_k/top_100_categorical_accuracy: 0.7783 - loss: 3668.3153 - regularization_loss: 0.0000e+00 - total_loss: 3668.3153\n",
      "Epoch 2/3\n",
      "472/472 [==============================] - 128s 271ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0873 - factorized_top_k/top_5_categorical_accuracy: 0.2234 - factorized_top_k/top_10_categorical_accuracy: 0.3209 - factorized_top_k/top_50_categorical_accuracy: 0.6984 - factorized_top_k/top_100_categorical_accuracy: 0.8198 - loss: 3475.8531 - regularization_loss: 0.0000e+00 - total_loss: 3475.8531\n",
      "Epoch 3/3\n",
      " 42/472 [=>............................] - ETA: 1:55 - factorized_top_k/top_1_categorical_accuracy: 0.0702 - factorized_top_k/top_5_categorical_accuracy: 0.2198 - factorized_top_k/top_10_categorical_accuracy: 0.3279 - factorized_top_k/top_50_categorical_accuracy: 0.7356 - factorized_top_k/top_100_categorical_accuracy: 0.8411 - loss: 3789.1562 - regularization_loss: 0.0000e+00 - total_loss: 3789.1562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/engine/training.py:1789\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1788\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1789\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:1155\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Updates the progbar.\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m-> 1155\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_init_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_steps:\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/callbacks.py:1130\u001b[0m, in \u001b[0;36mProgbarLogger._maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics)\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;66;03m# Update the existing stateful metrics as `self.model.metrics` may\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# contain updated metrics after `MetricsContainer` is built in the\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# first train step.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics\u001b[38;5;241m.\u001b[39munion(\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28mset\u001b[39m(m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m)\n\u001b[1;32m   1131\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar \u001b[38;5;241m=\u001b[39m Progbar(\n\u001b[1;32m   1135\u001b[0m         target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget,\n\u001b[1;32m   1136\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1137\u001b[0m         stateful_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics,\n\u001b[1;32m   1138\u001b[0m         unit_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_steps \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/engine/training.py:916\u001b[0m, in \u001b[0;36mModel.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m         metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_layers():\n\u001b[1;32m    917\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mextend(l\u001b[38;5;241m.\u001b[39m_metrics)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/engine/base_layer.py:3306\u001b[0m, in \u001b[0;36mLayer._flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_flatten_layers\u001b[39m(\u001b[38;5;28mself\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_self\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 3306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_modules(\n\u001b[1;32m   3307\u001b[0m         recursive\u001b[38;5;241m=\u001b[39mrecursive, include_self\u001b[38;5;241m=\u001b[39minclude_self\n\u001b[1;32m   3308\u001b[0m     ):\n\u001b[1;32m   3309\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Layer):\n\u001b[1;32m   3310\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfrs/lib/python3.9/site-packages/keras/src/engine/base_layer.py:3335\u001b[0m, in \u001b[0;36mLayer._flatten_modules\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trackable_id \u001b[38;5;129;01min\u001b[39;00m seen_object_ids:\n\u001b[1;32m   3334\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3335\u001b[0m \u001b[43mseen_object_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrackable_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;66;03m# Metrics are not considered part of the Layer's topology.\u001b[39;00m\n\u001b[1;32m   3338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trackable_obj, tf\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3339\u001b[0m     trackable_obj, metrics_mod\u001b[38;5;241m.\u001b[39mMetric\n\u001b[1;32m   3340\u001b[0m ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ec92a9c-0739-4c87-812d-5341c8d08d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472/472 [==============================] - 114s 240ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0677 - factorized_top_k/top_5_categorical_accuracy: 0.2839 - factorized_top_k/top_10_categorical_accuracy: 0.4216 - factorized_top_k/top_50_categorical_accuracy: 0.8063 - factorized_top_k/top_100_categorical_accuracy: 0.8935 - loss: 3035.4466 - regularization_loss: 0.0000e+00 - total_loss: 3035.4466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06774871796369553,\n",
       " 0.28385159373283386,\n",
       " 0.4216342866420746,\n",
       " 0.8062613010406494,\n",
       " 0.8935382962226868,\n",
       " 1991.751953125,\n",
       " 0,\n",
       " 1991.751953125]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547bfb2-653b-41c8-8f4a-22756dac2def",
   "metadata": {},
   "source": [
    "# 6. Model save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d990d2f4-1d63-402f-8980-0e153b632c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ‰øùÂ≠òÊùÉÈáçÔºàÂåÖÊã¨ user_model Âíå item_model ÁöÑÊâÄÊúâÂèÇÊï∞Ôºâ\n",
    "# model.save_weights(\"retrieval_weights\")\n",
    "\n",
    "# # ÂçïÁã¨‰øùÂ≠ò user_model\n",
    "# model.user_model.save(\"user_model\")\n",
    "# model.item_model.save(\"item_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2291a094-78c6-4a43-b1d9-af28e8d71000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Âä†ËΩΩ user/item Â°î\n",
    "# loaded_user_model = tf.keras.models.load_model(\"user_model\")\n",
    "# loaded_item_model = tf.keras.models.load_model(\"item_model\")\n",
    "\n",
    "# # ÈáçÊñ∞ÊûÑÂª∫ TwoTowerModel Âπ∂Âä†ËΩΩÊùÉÈáç\n",
    "# model = TwoTowerModel(loaded_user_model, loaded_item_model, candidate_ds)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "# model.load_weights(\"retrieval_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2f097-ff5a-4347-bc31-8c048171705b",
   "metadata": {},
   "source": [
    "# 7. Analysis model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4864e-a839-49da-b9cf-ffe1cf23434c",
   "metadata": {},
   "source": [
    "## Check the new user prediction ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f930caa2-fc81-43be-946d-aa1e3189b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ids = set(df_after[\"Email\"]) - set(df_before[\"Email\"])\n",
    "df_new_users = df_after[df_after[\"Email\"].isin(new_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "041d5860-7552-4e91-b3ce-054743cd0b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71454, 191264)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after[\"Email\"].nunique(),df_before[\"Email\"].nunique(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc0c314a-eaa7-4830-8fc7-05b1b5b211e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54860"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7aeaed23-c3f5-4c29-8f8c-619846b0fcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166472, 31)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c8ea3f5e-aa29-4db3-8984-535bb36afe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x327cc5c10>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    candidate_ds.batch(256).map(lambda x: (x[\"item_id\"], model.item_model(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5013e99-79de-459f-8a6f-6ddf74abffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1828/1828 [03:09<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColdStart HitRate@10: 0.0055  (10/1828)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "# ÊèêÂèñÂÄôÈÄâÂïÜÂìÅÁöÑ embedding Âíå id\n",
    "all_item_embs = []\n",
    "all_item_ids = []\n",
    "\n",
    "for batch in candidate_ds.batch(128):\n",
    "    all_item_embs.append(model.item_model(batch))\n",
    "    all_item_ids.append(batch[\"item_id\"])\n",
    "\n",
    "item_embeddings = tf.concat(all_item_embs, axis=0)\n",
    "item_ids = tf.concat(all_item_ids, axis=0)\n",
    "\n",
    "# ÈöèÊú∫ÈááÊ†∑Êñ∞Áî®Êà∑\n",
    "sample_emails = random.sample(\n",
    "    df_new_users[\"Email\"].unique().tolist(),\n",
    "    len(df_new_users[\"Email\"].unique()) // 30\n",
    ")\n",
    "\n",
    "hit_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for user_id in tqdm(sample_emails):\n",
    "    user_df = df_new_users[df_new_users[\"Email\"] == user_id]\n",
    "    if user_df.empty:\n",
    "        continue\n",
    "\n",
    "    user_dict = {\n",
    "        \"user_id\": tf.constant([user_id]),\n",
    "        \"province\": tf.constant([str(user_df[\"Shipping Province\"].iloc[0])]),\n",
    "        \"city\": tf.constant([str(user_df[\"Shipping City\"].iloc[0])]),\n",
    "        \"company\": tf.constant([str(user_df[\"Shipping Company\"].iloc[0])]),\n",
    "        \"hour\": tf.constant([str(user_df[\"Hour\"].iloc[0])]),\n",
    "        \"month\": tf.constant([str(user_df[\"Month\"].iloc[0])]),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # ÊâãÂä®Ëé∑ÂèñÂÜ∑ÂêØÂä®ÁöÑ user embeddingÔºàÂÖ≥Èó≠ user_idÔºâ\n",
    "        user_emb = model.user_model(user_dict, cold_start=True)  # ‚úÖ ‰ΩøÁî® cold_start=True\n",
    "        scores = tf.linalg.matmul(user_emb, item_embeddings, transpose_b=True)\n",
    "        top_scores, top_indices = tf.math.top_k(scores, k=top_k)\n",
    "\n",
    "        topk_items = set([x.numpy().decode(\"utf-8\") for x in tf.gather(item_ids, top_indices[0])])\n",
    "        true_items = set(user_df[\"Lineitem name\"].astype(str))\n",
    "\n",
    "        if topk_items & true_items:\n",
    "            hit_count += 1\n",
    "        total_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error for user {user_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "hit_rate = hit_count / total_count if total_count > 0 else 0\n",
    "print(f\"ColdStart HitRate@{top_k}: {hit_rate:.4f}  ({hit_count}/{total_count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463ee62-fad0-4bea-b402-dd27657aea32",
   "metadata": {},
   "source": [
    "+ HitRate@10: 0.0159  (87/5486)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55aeab-7aa8-4749-b53b-5d32bb822a3f",
   "metadata": {},
   "source": [
    "ColdStart HitRate@10: 0.0055  (10/1828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08e164-3783-4aa3-bef8-3b4683085f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dac816a3",
   "metadata": {},
   "source": [
    "## Old user purchased prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "12c250ea-a310-4041-a543-4f27022d670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "top_k = 10\n",
    "hit_count = 0\n",
    "total_count = 0\n",
    "\n",
    "# ÊâæÂá∫Âá∫Áé∞Âú®‰∏§‰∏™Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÁî®Êà∑\n",
    "common_emails = list(set(df_after[\"Email\"]) & set(df_before[\"Email\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc036a68-87b8-4a9f-8916-85b5c6c42f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16594"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a2c2b54-08c3-4faf-8b3a-725798a695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰Ω†ÂèØ‰ª•Âè™ÈááÊ†∑‰∏ÄÈÉ®ÂàÜÁî®‰∫éÊµãËØï\n",
    "sample_emails = random.sample(common_emails, len(common_emails) // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c1ab5c95-621e-433d-9e5a-eac634517453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7af78d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1659/1659 [03:07<00:00,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer HitRate@10: 0.0199  (33/1659)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for user_id in tqdm(sample_emails):\n",
    "    # ÂèñÊóßÊï∞ÊçÆ‰∏≠ËØ•Áî®Êà∑ÁöÑÁîªÂÉèÔºàÂÅáËÆæÂÆÉ‰Ωú‰∏∫Ê®°ÂûãËæìÂÖ•Ôºâ\n",
    "    user_df_before = df_before[df_before[\"Email\"] == user_id]\n",
    "    user_df_after = df_after[df_after[\"Email\"] == user_id]\n",
    "\n",
    "    if user_df_before.empty or user_df_after.empty:\n",
    "        continue\n",
    "\n",
    "    # ÊûÑÈÄ†Áî®Êà∑ÁîªÂÉèÔºà‰ΩøÁî® before ‰∏≠ÁöÑ‰ø°ÊÅØÔºâ\n",
    "    user_dict = {\n",
    "        \"user_id\": tf.constant([user_id]),\n",
    "        \"province\": tf.constant([str(user_df_before[\"Shipping Province\"].iloc[0])]),\n",
    "        \"city\": tf.constant([str(user_df_before[\"Shipping City\"].iloc[0])]),\n",
    "        \"company\": tf.constant([str(user_df_before[\"Shipping Company\"].iloc[0])]),\n",
    "        \"hour\": tf.constant([str(user_df_before[\"Hour\"].iloc[0])]),\n",
    "        \"month\": tf.constant([str(user_df_before[\"Month\"].iloc[0])]),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Ëé∑ÂèñÊé®ËçêÂïÜÂìÅ Top-K\n",
    "        scores, items = index(user_dict)\n",
    "        topk_items = set([x.decode(\"utf-8\") for x in items[0, :top_k].numpy()])\n",
    "\n",
    "        # ÁúüÂÆûÁöÑÊñ∞Ë¥≠‰π∞ÂïÜÂìÅ\n",
    "        true_items = set(user_df_after[\"Lineitem name\"].astype(str))\n",
    "\n",
    "        if topk_items & true_items:\n",
    "            hit_count += 1\n",
    "        total_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for user {user_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "hit_rate = hit_count / total_count if total_count > 0 else 0\n",
    "print(f\"Transfer HitRate@{top_k}: {hit_rate:.4f}  ({hit_count}/{total_count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329da225-6a01-4fbe-b49b-862145b55cea",
   "metadata": {},
   "source": [
    "## For a new product: EZ Planter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c6cbea9-7bff-4653-99f4-9f630e5580a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆ°ÁÆó after Âíå before ÁöÑÂÖ±ÂêåÁî®Êà∑\n",
    "all_old_users = set(df_before[\"Email\"].unique()) & set(df_after[\"Email\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "26376edd-605c-49a2-814d-1790c0049050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_before[\"Email\"].unique()),len(df_after[\"Email\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f7ef9b6-e97d-44bd-b82f-c7d688c0ad31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16594"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_old_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4237c953-4c37-4f2b-a892-04741e8217c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ëé∑ÂèñÂÖ±ÂêåÁî®Êà∑\n",
    "common_users = list(set(df_before[\"Email\"]) & set(df_after[\"Email\"]))\n",
    "\n",
    "# ÊèêÂèñÊØè‰∏™Â≠óÊÆµÁöÑÂÄºÔºàÂèñÁ¨¨‰∏ÄË°åÔºâ\n",
    "user_df_before = df_before[df_before[\"Email\"].isin(common_users)]\n",
    "user_features = user_df_before.groupby(\"Email\").first().reset_index()\n",
    "\n",
    "# ÊûÑÈÄ† batch ËæìÂÖ•\n",
    "user_dict = {\n",
    "    \"user_id\": tf.constant(user_features[\"Email\"].astype(str).tolist()),\n",
    "    \"province\": tf.constant(user_features[\"Shipping Province\"].astype(str).tolist()),\n",
    "    \"city\": tf.constant(user_features[\"Shipping City\"].astype(str).tolist()),\n",
    "    \"company\": tf.constant(user_features[\"Shipping Company\"].astype(str).tolist()),\n",
    "    \"hour\": tf.constant(user_features[\"Hour\"].astype(str).tolist()),\n",
    "    \"month\": tf.constant(user_features[\"Month\"].astype(str).tolist()),\n",
    "}\n",
    "\n",
    "# ‰∏ÄÊ¨°ÊÄßËé∑Âèñ embedding\n",
    "user_embeddings = model.user_model(user_dict).numpy()\n",
    "\n",
    "# Êò†Â∞ÑÂõû user_id -> embedding\n",
    "user_vectors = dict(zip(user_features[\"Email\"], user_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "814eb820-3987-44f5-8bac-7fa55df3d2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderid', 'Email', 'Lineitem sku', 'Lineitem name', 'Lineitem price',\n",
       "       'Subtotal', 'Shipping', 'Taxes', 'Total', 'Discount Amount',\n",
       "       'Created at', 'Lineitem quantity', 'Lineitem compare at price',\n",
       "       'Shipping Name', 'Shipping Street', 'Shipping Address1',\n",
       "       'Shipping Address2', 'Shipping Company', 'Shipping City',\n",
       "       'Shipping Zip', 'Shipping Province', 'Shipping Country',\n",
       "       'Shipping Phone', 'Vendor', 'Year', 'Month', 'Day', 'Hour', 'type name',\n",
       "       'Parent_SKU', 'Product Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93bb44c1-167c-4b08-a74b-21f3a1d11eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 9126, Test users: 7468\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Êñ∞ÂìÅÂêçÁß∞\n",
    "new_item = \"EZ Self-Watering Herb Planter Box with Trellis\"\n",
    "\n",
    "# ËÆ°ÁÆó after Âíå before ÁöÑÂÖ±ÂêåÁî®Êà∑\n",
    "all_old_users = set(df_before[\"Email\"].unique()) & set(df_after[\"Email\"].unique())\n",
    "\n",
    "# Ê≠£Ê†∑Êú¨ÔºöËÄÅÁî®Êà∑‰∏≠‰π∞‰∫ÜÊñ∞ÂìÅÁöÑ\n",
    "positive_users = df_after[df_after[\"type name\"] == new_item][\"Email\"].unique()\n",
    "positive_users = list(set(positive_users) & all_old_users)\n",
    "\n",
    "# Ë¥üÊ†∑Êú¨ÔºöËÄÅÁî®Êà∑‰∏≠Ê≤°‰π∞ËøáÊñ∞ÂìÅÁöÑ\n",
    "negative_users = list(all_old_users - set(positive_users))\n",
    "\n",
    "# ÂàõÂª∫ÊúâÊ†áÁ≠æÁöÑÁî®Êà∑ÂàóË°®\n",
    "all_labeled_users = [(u, 1) for u in positive_users] + [(u, 0) for u in negative_users]\n",
    "\n",
    "# Êåâ Email 55% / 45% ÂàíÂàÜËÆ≠ÁªÉ‰∏éÊµãËØï\n",
    "emails = [u for u, _ in all_labeled_users]\n",
    "labels = [l for _, l in all_labeled_users]\n",
    "train_emails, test_emails, train_labels, test_labels = train_test_split(\n",
    "    emails, labels, test_size=0.45, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ\n",
    "train_user_labeled = list(zip(train_emails, train_labels))\n",
    "test_user_labeled = list(zip(test_emails, test_labels))\n",
    "\n",
    "print(f\"Train users: {len(train_user_labeled)}, Test users: {len(test_user_labeled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7806d512-b985-4f91-9df2-6ee3cf7147a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ËøáÊª§Êéâ user_vectors ‰∏≠‰∏çÂ≠òÂú®ÁöÑÁî®Êà∑ÔºàÊûÅ‰∏™Âà´ÂèØËÉΩÂá∫ÈîôÊàñÁº∫ÁúÅÔºâ\n",
    "train_user_labeled = [(u, l) for u, l in train_user_labeled if u in user_vectors]\n",
    "test_user_labeled = [(u, l) for u, l in test_user_labeled if u in user_vectors]\n",
    "\n",
    "# ÊûÑÂª∫ numpy array Ê†ºÂºèÊï∞ÊçÆ\n",
    "X_train = np.array([user_vectors[u] for u, _ in train_user_labeled])\n",
    "y_train = np.array([l for _, l in train_user_labeled])\n",
    "\n",
    "X_test = np.array([user_vectors[u] for u, _ in test_user_labeled])\n",
    "y_test = np.array([l for _, l in test_user_labeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5429ffcb-754c-4647-8b40-cf3da6b7ec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution: Counter({0: 8689, 1: 437})\n",
      "Test label distribution: Counter({0: 7110, 1: 358})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Train label distribution:\", Counter(train_labels))\n",
    "print(\"Test label distribution:\", Counter(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5be589-c5e6-4b43-9e5d-d110e5934748",
   "metadata": {},
   "source": [
    "### use LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5247d784-6e45-42fb-b3ac-07689444df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.584092126405999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.59      0.73      7110\n",
      "           1       0.06      0.48      0.10       358\n",
      "\n",
      "    accuracy                           0.58      7468\n",
      "   macro avg       0.51      0.53      0.41      7468\n",
      "weighted avg       0.91      0.58      0.70      7468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ëá™Âä®Âπ≥Ë°°Á±ªÂà´ÊùÉÈáç\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d11a93-cacc-4aed-aa19-4b7a1ef3b60d",
   "metadata": {},
   "source": [
    "+ ÂΩìÂâçÊ®°ÂûãÁöÑ recall = 0.48ÔºåËØ¥ÊòéÂëΩ‰∏≠‰∫ÜËøë‰∏ÄÂçäÁöÑÊΩúÂú®ÂÆ¢Êà∑Ôºå‰ΩÜ precision = 0.06ÔºåËØ¥ÊòéÊé®ËçêÁªôÂ§™Â§ö‰∏ç‰π∞ÁöÑ‰∫∫‰∫Ü„ÄÇ\n",
    "+ ÊØîËµ∑ accuracyÔºåÊõ¥Â∫îËØ•‰ºòÂåñ precision„ÄÅrecall„ÄÅf1 Êàñ AUC„ÄÇ\n",
    "+ ÊØîÈöèÊú∫Êé®ËçêÂº∫ÂæàÂ§öÊâçÊúâÂÆûÁî®‰ª∑ÂÄºÔºöÂΩìÂâç precision = 6%Ôºåbaseline ÊòØ 4.8%ÔºåÂ∑ÆË∑ùÂæàÂ∞èÔºåÈúÄË¶Å‰ºòÂåñ„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571158c-53d4-45a9-a6fe-c38246404e44",
   "metadata": {},
   "source": [
    "+ The current model‚Äôs recall is 0.48, indicating that it captures nearly half of the potential customers, but the precision is only 0.06, meaning that it recommends to too many people who are unlikely to purchase.\n",
    "+ Compared to accuracy, it is more important to optimize precision, recall, F1 score, or AUC.\n",
    "+ The model must significantly outperform random recommendation to be practically valuable: the current precision is 6%, while the baseline is 4.8%, showing only a small improvement and requiring further optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "71b3dd5b-3d7d-4e9f-beb1-9a0c95305e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# clf = XGBClassifier(\n",
    "#     scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),  # Á±ªÂà´ÊùÉÈáç\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric=\"logloss\"\n",
    "# )\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "# y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39d1da-169f-40b8-89c3-2a0e405d478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1e83d6b-712c-44b0-a13d-22e3e500e4d5",
   "metadata": {},
   "source": [
    "### use mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8fba48e0-501f-45ce-a740-c1c0fc22bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4a9b2b7e-86dd-4935-94cc-bdcd365f551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜ\n",
    "X_train = np.array([user_vectors[email] for email, _ in train_user_labeled])\n",
    "y_train = np.array([label for _, label in train_user_labeled])\n",
    "\n",
    "# ÊûÑÈÄ†ÊµãËØïÈõÜ\n",
    "X_test = np.array([user_vectors[email] for email, _ in test_user_labeled])\n",
    "y_test = np.array([label for _, label in test_user_labeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f973b0ef-4532-4b5f-b88e-cd5b622077fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ËΩ¨Êç¢‰∏∫ PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# ÊûÑÂª∫ TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# ÊûÑÂª∫ DataLoaderÔºàbatch_size ÂèØË∞ÉÔºâ\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a54dee08-160f-47a0-8540-630eea36c0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9126, 64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ad2b993c-870b-4691-9640-296dfa47e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction=\"none\")\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a563f389-d56d-4034-9d8e-e2635ba9852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32]):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(last_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            last_dim = h\n",
    "        layers.append(nn.Linear(last_dim, 1))  # ËæìÂá∫ÊòØlogits\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81c50c15-aeff-4af2-a607-54e65b474e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, epochs=10, lr=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    pos_weight = torch.tensor([20.0])  # Ê≠£Á±ªÊØîË¥üÁ±ªÂ∞ë 20 ÂÄçÊó∂\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)\n",
    "    # criterion = FocalLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # È™åËØÅÈò∂ÊÆµ\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb)\n",
    "            probs = torch.sigmoid(preds)\n",
    "            all_preds.extend((probs > 0.5).cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6280c9a9-a0d2-4275-a2a2-5598847a2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = MLPClassifier(input_dim=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "106671f5-4379-4491-b618-b8533f7d56cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.3209\n",
      "Epoch 2: Train Loss = 1.3192\n",
      "Epoch 3: Train Loss = 1.3017\n",
      "Epoch 4: Train Loss = 1.2957\n",
      "Epoch 5: Train Loss = 1.2789\n",
      "Epoch 6: Train Loss = 1.2671\n",
      "Epoch 7: Train Loss = 1.2571\n",
      "Epoch 8: Train Loss = 1.2472\n",
      "Epoch 9: Train Loss = 1.2176\n",
      "Epoch 10: Train Loss = 1.2112\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9583    0.5848    0.7264      7110\n",
      "         1.0     0.0566    0.4944    0.1015       358\n",
      "\n",
      "    accuracy                         0.5805      7468\n",
      "   macro avg     0.5074    0.5396    0.4139      7468\n",
      "weighted avg     0.9151    0.5805    0.6964      7468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds, all_labels = train_and_evaluate(model, train_loader, test_loader, epochs=10, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "36a758ca-0aa6-4d0b-b8d4-9be396848ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds, all_labels = train_and_evaluate(model, train_loader, test_loader, epochs=10, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "58e77529-47ad-44d5-a1b1-bc91b5410c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives (TN): 4158\n",
      "False Positives (FP): 2952\n",
      "False Negatives (FN): 181\n",
      "True Positives (TP): 177\n",
      "Ê®°ÂûãÈ¢ÑÊµã‰∏∫‚Äú‰ºö‰π∞‚ÄùÁöÑ‰∫∫Êï∞: 3129\n",
      "Ê®°ÂûãÈ¢ÑÊµãÂØπÁöÑ‚Äú‰ºö‰π∞‚ÄùÁöÑ‰∫∫Êï∞ (ÁúüÊ≠£‰æã): 177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ÂÅáËÆæ all_labels Âíå all_preds ÊòØÂàóË°®Êàñ numpy Êï∞ÁªÑ\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"Ê®°ÂûãÈ¢ÑÊµã‰∏∫‚Äú‰ºö‰π∞‚ÄùÁöÑ‰∫∫Êï∞: {tp + fp}\")\n",
    "print(f\"Ê®°ÂûãÈ¢ÑÊµãÂØπÁöÑ‚Äú‰ºö‰π∞‚ÄùÁöÑ‰∫∫Êï∞ (ÁúüÊ≠£‰æã): {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e7c1d70d-89c4-48cf-bac7-44b1e36971b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7468"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFRS (tf 2.14)",
   "language": "python",
   "name": "tfrs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "nbTranslate": {
   "displayLangs": [
    "zh-CN",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "zh-CN",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
